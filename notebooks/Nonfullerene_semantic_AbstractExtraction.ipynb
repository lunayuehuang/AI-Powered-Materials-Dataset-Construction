{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3bc0670",
   "metadata": {},
   "source": [
    "# Data Mining For Materials Science from published litterature\n",
    "\n",
    "Here goes some text describing the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90e77ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from xml.etree import ElementTree as ET\n",
    "import pandas as pd\n",
    "import json\n",
    "from semanticscholar import SemanticScholar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "368cab05",
   "metadata": {},
   "outputs": [],
   "source": [
    "APIKey = '<Include your Elsevier API Key here>' ## Elsevier API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c25fbbb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>doi</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10.1063/1.2899996</td>\n",
       "      <td>American Institute of Physics (AIP)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10.1002/adma.200602496</td>\n",
       "      <td>Wiley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10.1021/ja710079w</td>\n",
       "      <td>American Chemical Society Publications (ACS)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10.1038/ncomms6293</td>\n",
       "      <td>Nature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>10.1038/NPHOTON.2009.192</td>\n",
       "      <td>Nature</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  paper_id                       doi  \\\n",
       "0        1         10.1063/1.2899996   \n",
       "1        2    10.1002/adma.200602496   \n",
       "2        3         10.1021/ja710079w   \n",
       "3        4        10.1038/ncomms6293   \n",
       "4        5  10.1038/NPHOTON.2009.192   \n",
       "\n",
       "                                         source  \n",
       "0           American Institute of Physics (AIP)  \n",
       "1                                         Wiley  \n",
       "2  American Chemical Society Publications (ACS)  \n",
       "3                                        Nature  \n",
       "4                                        Nature  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doi_list = pd.read_csv('../data/Saeki_papers_doi.csv',names=['paper_id', 'doi', 'source'])\n",
    "doi_list.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f174e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elsevier_dois = {}\n",
    "for i in range(doi_list.shape[0]):\n",
    "    doi = doi_list.loc[i]\n",
    "    if doi['source'] == 'Elsevier':\n",
    "        elsevier_dois[doi['paper_id']] = doi['doi']\n",
    "\n",
    "#print(elsevier_dois)\n",
    "len(elsevier_dois)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58727a8a",
   "metadata": {},
   "source": [
    "## download figures and save them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d26dc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_folder = './elsevier_papers/'\n",
    "image_folder = './elsevier_images/'\n",
    "\n",
    "object_tag = '{http://www.elsevier.com/xml/svapi/article/dtd}object'\n",
    "jpeg_id_attrib = 'multimediatype'\n",
    "jpeg_id_value = 'JPEG image file'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4a3f66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for paper_id, doi in elsevier_dois.items():\n",
    "    # download paper \n",
    "    paper_name = paper_folder + paper_id + '.xml'\n",
    "    paper_url = \"https://api.elsevier.com/content/article/doi/\" + doi + '?' + APIKey\n",
    "    data = requests.get(paper_url)\n",
    "    paper = ET.ElementTree(ET.fromstring(data.content))\n",
    "    paper.write(paper_name)\n",
    "    \n",
    "    # find image and download\n",
    "    object_lists = paper.iter(object_tag)\n",
    "    image_name_prefix = image_folder + paper_id + '_'\n",
    "    for obj in object_lists:\n",
    "        if obj.attrib[jpeg_id_attrib] == jpeg_id_value:\n",
    "            jpeg_name = image_name_prefix + obj.attrib['ref'] + '.jpeg'\n",
    "            jpeg_url = obj.text + '&' + APIKey\n",
    "            jpeg = requests.get(jpeg_url)\n",
    "            with open(jpeg_name, 'wb') as f:\n",
    "                f.write(jpeg.content)\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abeb39c5",
   "metadata": {},
   "source": [
    "## do search with elsevier api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed42728c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPV\n",
      "Query Page: 1\n",
      "Query Page: 3\n",
      "Query Page: 5\n",
      "Query Page: 7\n",
      "Query Page: 9\n",
      "Query Page: 11\n",
      "Query Page: 13\n",
      "Query Page: 15\n",
      "Query Page: 17\n",
      "Query Page: 19\n",
      "Query Page: 21\n",
      "Query Page: 23\n",
      "Query Page: 25\n",
      "Query Page: 27\n",
      "Query Page: 29\n",
      "Query Page: 31\n",
      "Query Page: 33\n",
      "Query Page: 35\n",
      "Query Page: 37\n",
      "Query Page: 39\n",
      "Query Page: 41\n",
      "Query Page: 43\n",
      "Query Page: 45\n",
      "Query Page: 47\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'entry'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-19cb13906000>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# Append the results from that page to our results set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0msearch_result_entries\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msearch_response_content\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'search-results'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'entry'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'entry'"
     ]
    }
   ],
   "source": [
    "search_key_words  = ['OPV'] \n",
    "total_number_of_results =  20000\n",
    "number_of_outputs_per_page = 25\n",
    "sorting = 'relevancy' #,pubyear'\n",
    "\n",
    "search_qs = '+AND+'.join(search_key_words)\n",
    "print(search_qs)\n",
    "search_url = f'https://api.elsevier.com/content/search/scopus?APIKey={APIKey}&query=KEY({search_qs})&count={number_of_outputs_per_page}&sort={sorting}'\n",
    "\n",
    "search_result_entries = []\n",
    "\n",
    "totalPage = int(total_number_of_results / number_of_outputs_per_page)\n",
    "nextpage = search_url\n",
    "\n",
    "search_result_entries = []\n",
    "\n",
    "for pageNum in range(totalPage):\n",
    "    \n",
    "    # skip even pages \n",
    "    if (pageNum + 1) % 2 == 0: continue\n",
    "        \n",
    "    # skip odd pages\n",
    "    #if pageNum % 2 == 1: continue\n",
    "    \n",
    "    print(f\"Query Page: {pageNum + 1}\")\n",
    "    query_url = search_url + '&start=' + str(number_of_outputs_per_page * pageNum)\n",
    "    \n",
    "    # Call the search API\n",
    "    search_response = requests.get(query_url)\n",
    "    search_response_content = json.loads(search_response.content)\n",
    "\n",
    "    # Append the results from that page to our results set\n",
    "    search_result_entries += search_response_content['search-results']['entry']\n",
    "\n",
    "    \n",
    "#date = '2011-2021'\n",
    "#search_url = search_url + '&date=' + date\n",
    "\n",
    "# start = 20\n",
    "# search_url = search_url + '&start=' + str(start)\n",
    "\n",
    "#search_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f46cb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPV\n",
      "Page: 1\n",
      "Page: 2\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'search-results'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-6f6ad7cef8cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# Append the results from that page to our results set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0msearch_result_entries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_response_content\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'search-results'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'entry'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# Check if there's a next page\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'search-results'"
     ]
    }
   ],
   "source": [
    "search_key_words  = ['OPV'] \n",
    "number_of_outputs = 25\n",
    "sorting = 'relevancy' #,pubyear'\n",
    "\n",
    "search_qs = '+AND+'.join(search_key_words)\n",
    "print(search_qs)\n",
    "search_url = f'https://api.elsevier.com/content/search/scopus?APIKey={APIKey}&query=KEY({search_qs})&count={number_of_outputs}&sort={sorting}'\n",
    "\n",
    "search_result_entries = []\n",
    "\n",
    "pageNum = 0\n",
    "\n",
    "nextpage = search_url\n",
    "while nextpage != None:\n",
    "    pageNum = pageNum + 1\n",
    "    print(f\"Page: {pageNum}\")\n",
    "\n",
    "    # Temporary limit to get only the first 3 pages.\n",
    "    if pageNum > 3:\n",
    "        break\n",
    "\n",
    "    # Call the search API\n",
    "    search_response = requests.get(nextpage)\n",
    "    search_response_content = json.loads(search_response.content)\n",
    "\n",
    "    # Append the results from that page to our results set\n",
    "    search_result_entries.append(search_response_content['search-results']['entry'])\n",
    "\n",
    "    # Check if there's a next page\n",
    "    nextpage = None\n",
    "    results_links = search_response_content['search-results']['link']\n",
    "    for link in results_links:\n",
    "        if link['@ref']== 'next':\n",
    "            nextpage = link['@href']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77288bbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'service-error': {'status': {'statusCode': 'AUTHENTICATION_ERROR',\n",
       "   'statusText': 'Invalid API Key'}}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_response_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5487e146",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_results_from_scopus_search(search_result, APIKey):\n",
    "    \n",
    "    if 'prism:doi' not in search_result.keys(): return None\n",
    "    doi         = search_result.get('prism:doi', 'N/A')\n",
    "    title       = search_result.get('dc:title', 'N/A')\n",
    "    year        = search_result.get('prism:coverDate', 'N/A').split('-')[0]\n",
    "    \n",
    "    #scopus_url  = search_result['prism:url'] + '?APIKey=' + APIKey\n",
    "    #headers = {'accept':'application/json'}\n",
    "    #details = requests.get(scopus_url,headers=headers)\n",
    "    #details_json = json.loads(details.text)['abstracts-retrieval-response']['coredata']\n",
    "        \n",
    "    #publisher   = details_json.get('dc:publisher', 'N/A')\n",
    "    #publication = details_json.get('prism:publicationName', 'N/A')\n",
    "    publisher = \"\"\n",
    "    publication = \"\"\n",
    "\n",
    "    return pd.DataFrame([[doi, publication, publisher, title, year]], columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d223c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['doi', 'publication', 'publisher', 'title', 'year']\n",
    "final_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for result in search_result_entries:\n",
    "    df = parse_results_from_scopus_search(result, APIKey)\n",
    "    #print(df)\n",
    "    if df is not None:\n",
    "        final_df = pd.concat([final_df, df], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9a6154e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(515, 5)\n",
      "                               doi                                publication  \\\n",
      "0       10.1186/s12859-021-04045-3                         BMC Bioinformatics   \n",
      "1  10.1016/j.commatsci.2021.110599            Computational Materials Science   \n",
      "2     10.1016/j.jlumin.2021.118192                    Journal of Luminescence   \n",
      "3      10.1016/j.ijleo.2021.166937                                      Optik   \n",
      "4      10.1016/j.jvacx.2021.100102                                 Vaccine: X   \n",
      "5       10.1007/s11664-021-09020-5            Journal of Electronic Materials   \n",
      "6       10.1016/j.xcrp.2021.100498              Cell Reports Physical Science   \n",
      "7           10.1002/anie.202102622  Angewandte Chemie - International Edition   \n",
      "8           10.1021/acsami.1c08487       ACS Applied Materials and Interfaces   \n",
      "9          10.3390/vaccines9070688                                   Vaccines   \n",
      "\n",
      "                   publisher  \\\n",
      "0         BioMed Central Ltd   \n",
      "1              Elsevier B.V.   \n",
      "2              Elsevier B.V.   \n",
      "3              Elsevier GmbH   \n",
      "4               Elsevier Ltd   \n",
      "5                   Springer   \n",
      "6                 Cell Press   \n",
      "7    John Wiley and Sons Inc   \n",
      "8  American Chemical Society   \n",
      "9                    MDPI AG   \n",
      "\n",
      "                                               title  year  \n",
      "0  In silico comparative study of SARS-CoV-2 prot...  2021  \n",
      "1  Algorithmically extracted morphology descripti...  2021  \n",
      "2  Cyano-substituted oligo (p-phenylene vinylene)...  2021  \n",
      "3  Effects of the photoactive layer properties an...  2021  \n",
      "4  Evaluation and validation of next-generation s...  2021  \n",
      "5  Optimization of Nanoparticle Organic Photovolt...  2021  \n",
      "6  Non-fullerene acceptor photostability and its ...  2021  \n",
      "7  Impact of Electrostatic Interaction on Bulk Mo...  2021  \n",
      "8  Tricyclic or Pentacyclic D Units: Design of D-...  2021  \n",
      "9  Development of a quantitative one-step rt-pcr ...  2021  \n"
     ]
    }
   ],
   "source": [
    "print(final_df.shape)\n",
    "print(final_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9612275f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save search_results\n",
    "final_df_name = 'scopus_search_results_odd_pages_before_page46.csv'\n",
    "final_df.to_csv(final_df_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35acdabf",
   "metadata": {},
   "source": [
    "## Now that we have search results, let's retrieve the abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "feaae373-c522-4424-8e4c-8b3e0c86c7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.read_csv('../data/search_results_photovoltaicANDdonor_with_abstract.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4dabbcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieves a paper from the semantic scholar database given its {paperid}. \n",
    "# attempts it up to {retries} times and each attempt times out after {timeout}\n",
    "sch = SemanticScholar()\n",
    "def force_get_paper(paperid, retries = 3, timeout = 15):\n",
    "    paperid = str(paperid)\n",
    "    if retries == 0:\n",
    "        return None\n",
    "    try:\n",
    "        return sch.get_paper(paperid, timeout=timeout)\n",
    "    except:\n",
    "        print(f'timeout: retrying request for paper id {paperid}. retries: {retries}')\n",
    "        return force_get_paper(paperid, retries = retries-1, timeout = timeout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c183803",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts = []\n",
    "for paperid in final_df['doi']:\n",
    "    paper_details = force_get_paper(paperid)\n",
    "    try:\n",
    "        abstract = paper_details['abstract']\n",
    "    except:\n",
    "        abstract = \"\"\n",
    "    abstracts.append(abstract)\n",
    "\n",
    "final_df['Abstract'] = abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827f33bb-0451-4dff-90b7-593567591c32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7455978517cfdf5a9aae9eb9315a939b3c7c3501eb9d7c0d1e97d158f74c5f65"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
