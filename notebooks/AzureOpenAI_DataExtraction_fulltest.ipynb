{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai\n",
    "# %pip install pdfminer\n",
    "# %pip install pdfminer.six\n",
    "%pip install azure-ai-formrecognizer\n",
    "%pip install langchain\n",
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import requests\n",
    "import json\n",
    "import io\n",
    "import pandas as pd\n",
    "import math\n",
    "#import pdfminer.high_level\n",
    "#import pdfminer.layout\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.formrecognizer import FormRecognizerClient\n",
    "from azure.ai.formrecognizer import DocumentAnalysisClient\n",
    "import os\n",
    "from openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Intelligence\n",
    "Document intelligence is service available through Azure. It features many models that can extract infromation from files including PDF, HTML JPEG/JPG, PNG, BMP, TIFF, HEIF, and Microsoft Office \n",
    "\n",
    "We will use the **Layout** model, which allows us to extract text paragraph by paragraph, and extract data from tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = \"https://<your open ai endpoint>.cognitiveservices.azure.com/\" ##### here should be the endpoint of your azure subscription's OpenAI instance. \n",
    "api_key = \"<your key here>\" ##### here you will need to modify to your OpenAI aipkey, \n",
    "pdf_file_path = \"pdf_no_table/30.pdf\" ###### where you local pdf file you want to study, \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function uses the document intellegence API to extract infromation from the given file using the layout model. The result is an object of type analyzeResult, which is a hierarchical data structure containing the extracted information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracts text from pdf\n",
    "def analyze_pdf_with_form_recognizer(endpoint, api_key, file_path):\n",
    "    credential = AzureKeyCredential(api_key)\n",
    "    document_analysis_client = DocumentAnalysisClient(\n",
    "        endpoint=endpoint, credential=AzureKeyCredential(api_key)\n",
    "    )   \n",
    "\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        poller = document_analysis_client.begin_analyze_document(\"prebuilt-layout\", file)\n",
    "        result = poller.result()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By filtering out papers that arent from Wiley, Elsivier, or RSC, we get 213 papers\n",
    "\n",
    "Paper 23 is missing from the folder and has no DOI information\n",
    "\n",
    "When manually checking the results from paper 84, I found that the information in Saeki's dataset does not match the content of the paper. Since we do not have the correct paper I removed it from the analysis\n",
    "\n",
    "That means the total for this test is 211 papers\n",
    "\n",
    "Papers are stored in ./data/pdfs and should have file name X.pdf, where X is the paper id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_papers = pd.read_csv(\"tested_papers.csv\")\n",
    "# papers = available_papers[available_papers['paper_id'] > 64]['paper_id'].to_list()\n",
    "papers = available_papers['paper_id'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still missing 23, 84 is wrong paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for paper in papers:\n",
    "    result = analyze_pdf_with_form_recognizer(endpoint, api_key, f\"./data/pdfs/{paper}.pdf\")\n",
    "    output = result.to_dict()\n",
    "    with open(f'./data/jsons/{paper}.json', 'w') as json_file:\n",
    "        json.dump(output, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have an analyzeResult object, we can use the following function to generate a string containing the relevant text from the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate complete text from AnalyzeResult\n",
    "def complete_text_from_analyze_result(result):\n",
    "    complete_text = \"\"\n",
    "    for paragraph in result.paragraphs:\n",
    "        if paragraph.role != 'pageFooter' and paragraph.role != 'pageHeader':\n",
    "            recognized_text = paragraph.content\n",
    "            complete_text += recognized_text\n",
    "    return complete_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we save the analyze result as a JSON, and generate the text from that. This allows us to avoid needing to analyze the same document more than once while working with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate complete text from JSON\n",
    "def complete_text_from_JSON(number):\n",
    "    with open(f\"./data/jsons/{number}.json\") as file:\n",
    "        data = json.load(file)\n",
    "    complete_text = \"\"\n",
    "    for paragraph in data['paragraphs']:\n",
    "        if 'role' in list(paragraph.keys()):\n",
    "            if paragraph['role'] != 'pageHeader' and paragraph['role'] != 'pageFooter':\n",
    "                recognized_text = paragraph['content']\n",
    "                complete_text += recognized_text\n",
    "                complete_text += '\\n'\n",
    "        else:\n",
    "            recognized_text = paragraph['content']\n",
    "            complete_text += recognized_text\n",
    "            complete_text += '\\n'\n",
    "    return complete_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(complete_text_from_JSON(95))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure OpenAI\n",
    "We can use the Azure OpenAI API to obtain completions. We will use the most recent version of GPT-4, which offers the best performance and new features like parallel function calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AzureOpenAI(\n",
    "  azure_endpoint = \"https://data-mining-gpt.openai.azure.com/\",##### here should be the endpoint of your azure subscription's OpenAI instance. \n",
    "  api_key='554073e88efc4d498a5df75522139352', ##### here you will need to modify to your OpenAI aipkey, \n",
    "  api_version=\"2023-05-15\" ##### you can choose another version, you might need to find the version name in the documentation. \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools\n",
    "Tools are like function that the language model can call. They can be used to obtain reliable output or allow the model to do things like search the internet, interact with databases, or perform calcualtions. When a tool is called, the model will not provide a normal message. Instead, it will provide a list of tool calls, containing the output for each time the tool was called. Tools can be called multiple times in parallel and the response will contain the output from all calls.\n",
    "\n",
    "Our tool will make it so the language model returns a dictionary containing polymer name, values for the desired properties, and their units. The *metrics* list defines the desired properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define what values to be extracted from text. Can be changed by changing the metrics list\n",
    "\n",
    "metrics = ['power conversion efficiency (PCE)',\n",
    "            'open circuit voltage (VOC)', \n",
    "            'short circuit current density (JSC)', \n",
    "            'fill factor (FF)']\n",
    "\n",
    "# creates openAI tool for extracting data from text\n",
    "extract_info_function = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"extract_information\",\n",
    "                \"description\": \"extracts information about a polymer\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"polymer_name\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Name of the polymer\",\n",
    "                        }                        \n",
    "                    },\n",
    "                    \"required\": [\"polymer_name\"],\n",
    "                },\n",
    "            }\n",
    "    }\n",
    "]\n",
    "properties = extract_info_function[0]['function']['parameters']['properties']\n",
    "for metric in metrics:\n",
    "    properties[metric] = {\n",
    "                            \"type\": \"number\",\n",
    "                            \"description\": f\"Highest value of {metric} reported for the polymer\",\n",
    "                        }\n",
    "    properties[f\"{metric} unit\"] = {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": f\"units that {metric} is reported in\",\n",
    "                        }\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining a completion\n",
    "The following method generates a completion from the language model. We can choose the model, define what messages to send the model, and control the temperature. We can also provide any tools we want the model to be able to call. \n",
    "\n",
    "In our prompt to we ask the model to extract the desired metrics for each polymer. It is important to be clear and specific in the prompt to avoid unwanted behavior. We are also sure to provide the tool we defined earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(metrics, text):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"data-mining-4\", # model = \"deployment_name\".\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": f\"\"\"\n",
    "            You are a polymer scientist analyzing scientific papers. For the polymers studied in the paper, extract the following values: {metrics}. Report the highest value of {metrics[0]} and the corresponding values of the other metrics for each polymer. Do not make up any information. \n",
    "            \"\"\"}, ##### this is part of the prompt, which probably needs to be modified to get right answer. This system prompt tells the GPT AI what role it needs to play.\n",
    "            {\"role\": \"user\", \"content\": f\"Here is the paper to analyze: {text}\"},\n",
    "        ],\n",
    "        temperature = 0, ##### You might want to experiment with different values.\n",
    "        tools = extract_info_function\n",
    "    )\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to understand how much it costs to obtain responsed from the language models. We can calculate this from the number of tokens used for the prompt and completion, which are stored in the response object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates the cost to obtain a response from language model\n",
    "def calculate_cost(response):\n",
    "    if response.model == 'gpt-4':\n",
    "        output_price = 0.03/1000\n",
    "        input_price = 0.01/1000\n",
    "    else:\n",
    "        output_price = 0.0015/1000\n",
    "        input_price = 0.0005/1000\n",
    "    total_cost = response.usage.prompt_tokens * input_price + response.usage.completion_tokens * output_price\n",
    "    return total_cost\n",
    "\n",
    "# prints tokens used and total cost\n",
    "def print_usage(response):\n",
    "    \n",
    "    print('prompt tokens = ' + str(response.usage.prompt_tokens))\n",
    "    print('completion tokens = ' + str(response.usage.completion_tokens))\n",
    "    total_cost = calculate_cost(response)\n",
    "    print('total cost = $' + str(total_cost))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = \"The VOC of PMMA is 25 V. It's PCE is 15%. The same values for PVC are 40 V and 10%, respectively\"\n",
    "test_text2 = \"The VOC of PMMA is 25 V. It's PCE is 15%. The VOC of PVC is 14V\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtaining results\n",
    "Using the functions we have defined, we can now analyze multiple papers to create a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numbers of the papers being used, analyze result should be saved in the format X.pdf.json\n",
    "# If running from the start this should already be the case\n",
    "# papers = [1]\n",
    "# papers = [15,30,34,77,92,154,200,204,205,241,243,262,271,273,289,303,309,330,333,334]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(f\"./data/llm_cost.json\") as file:\n",
    "        cost = json.load(file)\n",
    "\n",
    "for paper in papers:\n",
    "    text = complete_text_from_JSON(paper)\n",
    "\n",
    "    results_table = pd.DataFrame()\n",
    "    results_table['paper_#'] = []\n",
    "    results_table['polymer_name'] = []\n",
    "    for metric in metrics:\n",
    "        results_table[metric] = []\n",
    "        results_table[f\"{metric} unit\"] = []\n",
    "    \n",
    "    response = extract_data(metrics, text)\n",
    "    cost += calculate_cost(response)\n",
    "    with open(f'./data/llm_cost.json', 'w') as json_file:\n",
    "        json.dump(cost, json_file, indent=4) \n",
    "    tool_calls = response.choices[0].message.tool_calls\n",
    "    for call in tool_calls:\n",
    "        current = json.loads(call.function.arguments)\n",
    "        current['paper_#'] = paper\n",
    "        results_table.loc[len(results_table)] = current\n",
    "    results_table.to_csv(f'./data/csv_from_text/{paper}.csv', sep='\\t', header=True, encoding='utf-8')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can save these results to a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_table.to_csv('results2.csv', sep='\\t', header=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_results_table(papers):\n",
    "    table = pd.DataFrame()\n",
    "    table['paper_#'] = []\n",
    "    table['polymer_name'] = []\n",
    "\n",
    "    for metric in metrics:\n",
    "        table[metric] = []\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    for paper in papers:\n",
    "        current_paper = pd.read_csv(f\"./data/csv_from_text/{paper}.csv\", sep='\\t', encoding='utf-8')\n",
    "        for index, row in current_paper.iterrows():\n",
    "            ff = row['fill factor (FF)']\n",
    "            if ff > 1:\n",
    "                ff = ff/100\n",
    "            new_row = [paper, row['polymer_name'], row['power conversion efficiency (PCE)'], row['open circuit voltage (VOC)'], row['short circuit current density (JSC)'], ff]\n",
    "            table.loc[len(table)] = new_row\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_table = build_results_table(papers)\n",
    "results_table.to_csv('./data/results_table_5.csv', sep='\\t', header=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check the results, we can also generate a subset of saeki's dataset containing information from the papers of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a list of integers corresponding to the ID's of the papers being looked at, \n",
    "# builds a dataframe from saeki's data set which only contains polymers from the \n",
    "# relevant papers and only relevant properties that are being extracted\n",
    "def build_saeki_table(papers):\n",
    "    table = pd.DataFrame()\n",
    "    table['polymer_name'] = []\n",
    "\n",
    "    for metric in metrics:\n",
    "        table[metric] = []\n",
    "    \n",
    "    table['paper_#'] = []\n",
    "\n",
    "    saeki = pd.read_csv(\"saeki's_dataset.csv\")\n",
    "    for paper in papers:\n",
    "        current_paper = saeki[saeki['Ref. No'] == f'S{paper}']\n",
    "        for index, row in current_paper.iterrows():\n",
    "            new_row = [row['Nickname'], row['PCE_max(%)'], row['Voc (V)'], row['Jsc (mA cm^2)'], row['FF'], paper]\n",
    "            table.loc[len(table)] = new_row\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saeki_table = build_saeki_table(papers)\n",
    "saeki_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saeki_table.to_csv('saeki_table_5.csv', sep='\\t', header=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code autimatically compares the two tables generate. However, sometimes there are slight differences between the names of the polymers, so importing the data to excel and manually matching the names is more reliable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Might need to fix the case where there are duplicates with the same polymer name\n",
    "accuracy = {\n",
    "    'polymers correct': 0, # Polymer was identified from paper\n",
    "    'polymers missed': 0, # Polymer was not identified from paper\n",
    "    'polymers extra': 0, # Polymer was identified from paper and not found in saeki's dataset\n",
    "    'values correct': 0, # Value extracted agrees with saeki's dataset\n",
    "    'values missed': 0, # Value was not extracted from text\n",
    "    'values incorrect': 0, # Value extracted does not agree with saeki's dataset\n",
    "    'values extra': 0 # Value for polymer not found in saeki's dataset \n",
    "}\n",
    "for index, results_row in results_table.iterrows():\n",
    "    saeki_row = saeki_table[saeki_table['polymer_name'] == results_row['polymer_name']]\n",
    "    results_row_list = results_row.tolist()\n",
    "    if len(saeki_row) == 0:\n",
    "        accuracy['polymers extra'] += 1\n",
    "        for i in range(0, len(metrics)):\n",
    "            if not math.isnan(results_row_list[i+1]):\n",
    "                accuracy['values extra'] += 1\n",
    "    else:\n",
    "        accuracy['polymers correct'] += 1\n",
    "        saeki_row_list = saeki_row.iloc[0].tolist()\n",
    "        for i in range(0, len(metrics)):\n",
    "            if math.isnan(results_row_list[i+1]):\n",
    "                accuracy['values missed'] += 1\n",
    "            elif saeki_row_list[i+1] == results_row_list[i+1]:\n",
    "                accuracy['values correct'] += 1\n",
    "            else:\n",
    "                accuracy['values incorrect'] +=1\n",
    "accuracy['polymers missed'] = len(saeki_table) - accuracy['polymers correct']        \n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
